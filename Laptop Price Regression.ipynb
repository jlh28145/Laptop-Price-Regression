{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# read in all our data\n",
    "laptop_train = pd.read_csv(\"datasets/laptops_train.csv\")\n",
    "laptop_test = pd.read_csv(\"datasets/laptops_test.csv\")\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(laptop_train.head())\n",
    "print(laptop_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [laptop_train,laptop_test]\n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of missing data points per column\n",
    "missing_values_count = df.isnull().sum()\n",
    "missing_values_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Operating System Version'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Operating System Version'].isna()].groupby('Operating System').groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('Operating System')\n",
    "\n",
    "for name,group in grouped:\n",
    "    print(name)\n",
    "    print(group['Operating System Version'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the Operating System Version because the laptop can just be updated by the user\n",
    "df = df.drop('Operating System Version', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Screen Size','Screen']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing\n",
    "Course of Action:\n",
    "Manufacturer         Target Encoding\n",
    "Model Name           Split on the () into two columns- Target Encoding\n",
    "Category             One Hot Encoding\n",
    "Screen Size          Convert to float and scale (units is inches)\n",
    "Screen               Split into new features - screen type, screen quality, HD(Binary), Touchscreen(Binary)\n",
    "CPU                  Split into new features - Brand, Model Number, Speed\n",
    "RAM                  Remove \"GB\" and scale\n",
    "Storage              Convert to Total Storage column and scale\n",
    "GPU                  Split into new features - Brand, Model Number, Speed\n",
    "Operating System     One Hot Encoding (macOS = MacOS)\n",
    "Weight               Convert to lbs and scale (4s = 4.04 typo)\n",
    "Price                Convert to USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Course of Action:\n",
    "#Manufacturer         Target Encoding\n",
    "#Model Name           Split on the () into two columns- Target Encoding\n",
    "#Category             One Hot Encoding\n",
    "#Screen Size          Convert to float and scale (units is inches)\n",
    "#Screen               Split into new features - screen type, screen quality, HD(Binary), Touchscreen(Binary)\n",
    "#CPU                  Split into new features - Brand, Model Number, Speed\n",
    "#RAM                  Remove \"GB\" and scale\n",
    "#Storage              Convert to Total Storage column and scale\n",
    "#GPU                  Split into new features - Brand, Model Number, Speed\n",
    "#Operating System     One Hot Encoding (macOS = MacOS)\n",
    "#Weight               Convert to lbs and scale (4s = 4.04 typo)\n",
    "#Price                Convert to USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treat Manufacturer as an nominal variable\n",
    "df['Manufacturer'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives a tuple of column name and series\n",
    "# for each column in the dataframe\n",
    "for (columnName, columnData) in df.items():\n",
    "    print('Column Name : ', columnName)\n",
    "    print('Column Contents : ', columnData.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = df['Model Name'].unique()\n",
    "model_name.sort()\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Model Name','CPU']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Model Name'].str.contains('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Yoga' in df['Model Name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Model Name'].str.contains('/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = df['Category'].unique()\n",
    "category.sort()\n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives a tuple of column name and series\n",
    "# for each column in the dataframe\n",
    "for (columnName, columnData) in df.items():\n",
    "    print('Column Name : ', columnName)\n",
    "    print('Column Contents : ', columnData.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_size = df['Screen Size'].unique()\n",
    "screen_size.sort()\n",
    "screen_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen = df['Screen'].unique()\n",
    "screen.sort()\n",
    "print(df['Screen'].value_counts())\n",
    "screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU = df['CPU'].unique()\n",
    "CPU.sort()\n",
    "print(df['CPU'].value_counts())\n",
    "CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAM = df['RAM'].unique()\n",
    "RAM.sort()\n",
    "print(df['RAM'].value_counts())\n",
    "RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = df[' Storage'].unique()\n",
    "storage.sort()\n",
    "print(df[' Storage'].value_counts())\n",
    "storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = df['GPU'].unique()\n",
    "GPU.sort()\n",
    "print(df['GPU'].value_counts())\n",
    "GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OS = df['Operating System'].unique()\n",
    "OS.sort()\n",
    "print(df['Operating System'].value_counts())\n",
    "OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = df['Weight'].unique()\n",
    "weight.sort()\n",
    "print(df['Weight'].value_counts())\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = df['Price'].unique()\n",
    "price.sort()\n",
    "print(df['Price'].value_counts())\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 INR = 0.012203 USD Conversion Rate as of May 10,2023\n",
    "df['Price_USD'] = df.Price/81.9433\n",
    "df.Price_USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Price','Price_USD']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target Encoding for Manfacturer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weight_LBS'] = df.Weight*2.204623\n",
    "df.Weight_LBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Weight = df.Weight.str.replace('kg','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Weight = df.Weight.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4s is a typo. Google search the weight of the laptop\n",
    "df.Weight = df.Weight.replace('4s','4.04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Weight','Weight_LBS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Operating System Typo\n",
    "df['Operating System'] = df['Operating System'].replace('macOS','Mac OS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RAM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clearing GB from string and converting to int\n",
    "df.RAM = df.RAM.str.replace('GB','')\n",
    "df.RAM = df.RAM.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Leading Space in Column Name\n",
    "df.rename(columns = {' Storage':'Storage'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Screen Size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clearing \" from string and converting to float\n",
    "df['Screen Size'] = df['Screen Size'].str.replace('\"','')\n",
    "df['Screen Size'] = df['Screen Size'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Pattern of the CPU string Brand, Model Number, and Speed\n",
    "Since the brand and model number vary in length\n",
    "The string will be flipped to take the Speed then\n",
    "take the brand from the front of the string \"\"\"\n",
    "CPU_df = df[['CPU']].copy()\n",
    "# Python code\n",
    "# To reverse words in a given string\n",
    "CPU_reversed = []\n",
    "# input string\n",
    "for x in CPU_df.CPU:\n",
    "    # reversing words in a given string\n",
    "    s = x.split()[::-1]\n",
    "    l = []\n",
    "    for i in s:\n",
    "        # appending reversed words to l\n",
    "        l.append(i)\n",
    "    # printing reverse words\n",
    "    CPU_reversed.append(\" \".join(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating New feature - CPU Speed\n",
    "CPU_df['CPU_reversed'] = CPU_reversed\n",
    "new = CPU_df['CPU_reversed'].str.split(' ', expand=True, n=2)\n",
    "df['CPU_Speed'] = new[0]\n",
    "df['CPU_Speed'] = df['CPU_Speed'].str.replace('GHz','')\n",
    "df['CPU_Speed'] = df['CPU_Speed'].astype(float)\n",
    "new['CPU_Flipped'] = new[1] + \" \" +new[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code\n",
    "# To reverse words in a given string\n",
    "CPU_flipped = []\n",
    "# input string\n",
    "for x in new.CPU_Flipped:\n",
    "    # reversing words in a given string\n",
    "    s = x.split()[::-1]\n",
    "    l = []\n",
    "    for i in s:\n",
    "        # appending reversed words to l\n",
    "        l.append(i)\n",
    "    # printing reverse words\n",
    "    CPU_flipped.append(\" \".join(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating New features - CPU Brand and Model\n",
    "new['CPU_flipped'] = CPU_flipped\n",
    "new2 = new['CPU_flipped'].str.split(' ', expand=True, n=1)\n",
    "df['CPU Brand'] = new2[0]\n",
    "df['CPU Model'] = new2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploring new features\n",
    "CPU_speed = df['CPU_Speed'].unique()\n",
    "CPU_speed.sort()\n",
    "print(df['CPU_Speed'].value_counts())\n",
    "CPU_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploring new features\n",
    "CPU_brand = df['CPU Brand'].unique()\n",
    "CPU_brand.sort()\n",
    "print(df['CPU Brand'].value_counts())\n",
    "CPU_brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploring new features\n",
    "CPU_model = df['CPU Model'].unique()\n",
    "CPU_model.sort()\n",
    "print(df['CPU Model'].value_counts())\n",
    "CPU_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new features - GPU Brand and Model from GPU\n",
    "new3 = df['GPU'].str.split(' ', expand=True, n=1)\n",
    "df['GPU Brand'] = new3[0]\n",
    "df['GPU Model'] = new3[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_model = df['GPU Model'].unique()\n",
    "GPU_model.sort()\n",
    "print(df['GPU Model'].value_counts())\n",
    "GPU_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_brand = df['GPU Brand'].unique()\n",
    "GPU_brand.sort()\n",
    "print(df['GPU Brand'].value_counts())\n",
    "GPU_brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some of the Model Names had redundant information captured in other columns\n",
    "new4 = df['Model Name'].str.split('(', expand=True, n=1)\n",
    "df['Model Name Cleaned'] = new4[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_c = df['Model Name Cleaned'].unique()\n",
    "model_name_c.sort()\n",
    "print(df['Model Name Cleaned'].value_counts())\n",
    "model_name_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new feature of whether the screen is touchscreen\n",
    "screen_touch = []\n",
    "\n",
    "for x in df.Screen:\n",
    "    if 'Touchscreen' in x:\n",
    "        screen_touch.append(1)\n",
    "    else:\n",
    "        screen_touch.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new feature of whether the screen is hd\n",
    "screen_hd = []\n",
    "\n",
    "for x in df.Screen:\n",
    "    if 'HD' in x:\n",
    "        screen_hd.append(1)\n",
    "    else:\n",
    "        screen_hd.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Touchscreen'] = screen_touch\n",
    "df['Screen_HD'] = screen_hd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new5 = df['Screen'].str.split(' ', expand=True)\n",
    "new5 = new5.fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new feature - screen quality from Screen column\n",
    "screen_quality = []\n",
    "for index,row in new5.iterrows():\n",
    "    screen_quality.append(row[row.str.contains('x')].values[0])\n",
    " #       screen_quality.append(row[index])\n",
    "  #  else:\n",
    "   #     screen_quality.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Screen Quality'] = screen_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_quality_cleaned = df['Screen Quality'].unique()\n",
    "screen_quality_cleaned.sort()\n",
    "print(df['Screen Quality'].value_counts())\n",
    "screen_quality_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Certain rows have multiple storage types and sizes.\n",
    "Combining multiple storage types into total storage in the TB units \"\"\"\n",
    "new6 = df['Storage'].str.split(' ', expand=True)\n",
    "storage = []\n",
    "for index,row in new6.iterrows():\n",
    "    storage.append(row[row.str.contains('B')].values)\n",
    "new6 = new6.fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_df = pd.DataFrame(storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_df = storage_df.fillna('0GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*(1024*1024*1024)\n",
    "#*(1024*1024*1024*1024)\n",
    "col_0 = []\n",
    "for val in storage_df[0]:\n",
    "    if 'GB' in val:\n",
    "        col_0.append(int(re.findall(r'\\d+',val)[0])*(1024*1024*1024))\n",
    "    elif 'TB' in val:\n",
    "        col_0.append(int(re.findall(r'\\d+',val)[0])*(1024*1024*1024*1024))\n",
    "    else:\n",
    "        print('Nothing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_1 = []\n",
    "for val in storage_df[1]:\n",
    "    if 'GB' in val:\n",
    "        col_1.append(int(re.findall(r'\\d+',val)[0])*(1024*1024*1024))\n",
    "    elif 'TB' in val:\n",
    "        col_1.append(int(re.findall(r'\\d+',val)[0])*(1024*1024*1024*1024))\n",
    "    else:\n",
    "        print('Nothing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list = [col_0[i] + col_1[i] for i in range(len(col_0))]\n",
    "total_storage_list = [x/(1024*1024*1024*1024) for x in res_list]\n",
    "df['Total Storage in TB'] = total_storage_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Storage','Total Storage in TB']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datasets/laptops_preprocessed.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('datasets/laptops_preprocessed.csv',index_col=0)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply(lambda x: int(x.split(' ')[0]))\n",
    "#Example of cleaner way to create new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objList = df.select_dtypes(include = \"object\").columns\n",
    "print (objList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding for object to numeric conversion\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "for feat in objList:\n",
    "    df[feat] = le.fit_transform(df[feat].astype(str))\n",
    "\n",
    "print (df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datasets/laptops_afterlabelencoder.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Model Name','Screen','CPU','Storage','GPU','Weight','Price','Price_USD'],axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.Price_USD\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr_clf = LinearRegression()\n",
    "lr_clf.fit(X_train,y_train)\n",
    "lr_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5,test_size=0.2, random_state=0)\n",
    "\n",
    "cross_val_score(LinearRegression(),X,y,cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor()\n",
      "\tTraining time: 0.002s\n",
      "\tPrediction time: 0.017s\n",
      "\tExplained variance: 0.7456339753457355\n",
      "\tMean absolute error: 25379.263703348657\n",
      "\tR2 score: 0.7446258061416231\n",
      "\n",
      "GradientBoostingRegressor()\n",
      "\tTraining time: 0.158s\n",
      "\tPrediction time: 0.002s\n",
      "\tExplained variance: 0.8831144798210268\n",
      "\tMean absolute error: 18919.316523457474\n",
      "\tR2 score: 0.8790154524455557\n",
      "\n",
      "KNeighborsRegressor()\n",
      "\tTraining time: 0.001s\n",
      "\tPrediction time: 0.012s\n",
      "\tExplained variance: 0.7456339753457355\n",
      "\tMean absolute error: 25379.263703348657\n",
      "\tR2 score: 0.7446258061416231\n",
      "\n",
      "ExtraTreesRegressor()\n",
      "\tTraining time: 0.352s\n",
      "\tPrediction time: 0.012s\n",
      "\tExplained variance: 0.9031180342930277\n",
      "\tMean absolute error: 16219.557399392028\n",
      "\tR2 score: 0.9005268273155099\n",
      "\n",
      "RandomForestRegressor()\n",
      "\tTraining time: 0.539s\n",
      "\tPrediction time: 0.015s\n",
      "\tExplained variance: 0.8868551479248608\n",
      "\tMean absolute error: 16854.727187884182\n",
      "\tR2 score: 0.8856871244724549\n",
      "\n",
      "DecisionTreeRegressor()\n",
      "\tTraining time: 0.008s\n",
      "\tPrediction time: 0.002s\n",
      "\tExplained variance: 0.826685961856734\n",
      "\tMean absolute error: 21839.547603716474\n",
      "\tR2 score: 0.826629537135732\n",
      "\n",
      "LinearRegression()\n",
      "\tTraining time: 0.005s\n",
      "\tPrediction time: 0.001s\n",
      "\tExplained variance: 0.725560267230712\n",
      "\tMean absolute error: 30155.814294576954\n",
      "\tR2 score: 0.7217659728141248\n",
      "\n",
      "Lasso()\n",
      "\tTraining time: 0.006s\n",
      "\tPrediction time: 0.002s\n",
      "\tExplained variance: 0.7255604589885247\n",
      "\tMean absolute error: 30155.72565182683\n",
      "\tR2 score: 0.7217660657129893\n",
      "\n",
      "Ridge()\n",
      "\tTraining time: 0.003s\n",
      "\tPrediction time: 0.001s\n",
      "\tExplained variance: 0.7256285639323394\n",
      "\tMean absolute error: 30148.174656189418\n",
      "\tR2 score: 0.7218344104344818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import explained_variance_score,mean_absolute_error,r2_score\n",
    "from time import time\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regressors = [\n",
    "    KNeighborsRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    KNeighborsRegressor(),\n",
    "    ExtraTreesRegressor(),\n",
    "    RandomForestRegressor(),\n",
    "    DecisionTreeRegressor(),\n",
    "    LinearRegression(),\n",
    "    Lasso(),\n",
    "    Ridge()\n",
    "]\n",
    "\n",
    "head = 10\n",
    "for model in regressors[:head]:\n",
    "    start = time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time() - start\n",
    "    start = time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    predict_time = time()-start    \n",
    "    print(model)\n",
    "    print(\"\\tTraining time: %0.3fs\" % train_time)\n",
    "    print(\"\\tPrediction time: %0.3fs\" % predict_time)\n",
    "    print(\"\\tExplained variance:\", explained_variance_score(y_test, y_pred))\n",
    "    print(\"\\tMean absolute error:\", mean_absolute_error(y_test, y_pred))\n",
    "    print(\"\\tR2 score:\", r2_score(y_test, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "                  'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "                  'n_estimators' : [100,500,1000, 1500],\n",
    "                  'max_depth'    : [4,6,8,10]\n",
    "                 }\n",
    "\n",
    "grid_GBR = GridSearchCV(estimator=GradientBoostingRegressor(), param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train)\n",
    "\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " ExtraTreesRegressor(criterion='mse', max_depth=50, max_features='sqrt',\n",
      "                    min_samples_split=4, n_estimators=50, warm_start=True)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.8254279245091919\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'bootstrap': False, 'criterion': 'mse', 'max_depth': 50, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 50, 'warm_start': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hinso\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10,50,100],\n",
    "    'criterion': ['mse', 'mae'],\n",
    "    'max_depth': [2,8,16,32,50],\n",
    "    'min_samples_split': [2,4,6],\n",
    "    'min_samples_leaf': [1,2],\n",
    "    #'oob_score': [True, False],\n",
    "    'max_features': ['auto','sqrt','log2'],    \n",
    "    'bootstrap': [True, False],\n",
    "    'warm_start': [True, False],\n",
    "}\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "model = ExtraTreesRegressor ()\n",
    "\n",
    "gcv = GridSearchCV(model,param_grid,cv=5,n_jobs=-1).fit(X_train,y_train)\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",gcv.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",gcv.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",gcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc=RandomForestRegressor(random_state=42)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['squared_error', 'absolute_error', 'friedman_mse', 'poisson']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",CV_rfc.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",CV_rfc.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters range intialization for tuning \n",
    "\n",
    "parameters={\"splitter\":[\"best\",\"random\"],\n",
    "            \"max_depth\" : [1,3,5,7,9,11,12],\n",
    "           \"min_samples_leaf\":[1,2,3,4,5,6,7,8,9,10],\n",
    "           \"min_weight_fraction_leaf\":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "           \"max_features\":[\"auto\",\"log2\",\"sqrt\",None],\n",
    "           \"max_leaf_nodes\":[None,10,20,30,40,50,60,70,80,90] }\n",
    "\n",
    "tuning_model=GridSearchCV(DecisionTreeRegressor(),param_grid=parameters,scoring='neg_mean_squared_error',cv=3,verbose=3)\n",
    "tuning_model.fit(X_train,y_train)\n",
    "\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",tuning_model.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",tuning_model.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",tuning_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " DecisionTreeRegressor(max_depth=9, max_features='log2', max_leaf_nodes=30,\n",
      "                      min_samples_leaf=5, min_weight_fraction_leaf=0.1)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " -2168990008.2128525\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'max_depth': 9, 'max_features': 'log2', 'max_leaf_nodes': 30, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.1, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",tuning_model.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",tuning_model.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",tuning_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The best estimator across ALL searched params:\n",
      " RandomForestRegressor(max_depth=8, max_features='sqrt', n_estimators=200,\n",
      "                      random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n The best estimator across ALL searched params:\\n\",CV_rfc.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hinso\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesRegressor(criterion='mse', max_depth=50, max_features='sqrt',\n",
      "                    min_samples_split=4, n_estimators=50, warm_start=True)\n",
      "\tTraining time: 0.082s\n",
      "\tPrediction time: 0.007s\n",
      "\tExplained variance: 0.8919367898716148\n",
      "\tMean absolute error: 16665.30493547048\n",
      "\tR2 score: 0.8890409259834438\n",
      "\n",
      "RandomForestRegressor(max_depth=8, max_features='sqrt', n_estimators=200,\n",
      "                      random_state=42)\n",
      "\tTraining time: 0.300s\n",
      "\tPrediction time: 0.016s\n",
      "\tExplained variance: 0.8486892426386257\n",
      "\tMean absolute error: 19978.59634288556\n",
      "\tR2 score: 0.8450947501712552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regressors = [\n",
    "    ExtraTreesRegressor(criterion='mse', max_depth=50, max_features='sqrt',\n",
    "                    min_samples_split=4, n_estimators=50, warm_start=True),\n",
    "    RandomForestRegressor(max_depth=8, max_features='sqrt', n_estimators=200,\n",
    "                      random_state=42)\n",
    "]\n",
    "\n",
    "head = 2\n",
    "for model in regressors[:head]:\n",
    "    start = time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time() - start\n",
    "    start = time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    predict_time = time()-start    \n",
    "    print(model)\n",
    "    print(\"\\tTraining time: %0.3fs\" % train_time)\n",
    "    print(\"\\tPrediction time: %0.3fs\" % predict_time)\n",
    "    print(\"\\tExplained variance:\", explained_variance_score(y_test, y_pred))\n",
    "    print(\"\\tMean absolute error:\", mean_absolute_error(y_test, y_pred))\n",
    "    print(\"\\tR2 score:\", r2_score(y_test, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hinso\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8843212901313946"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = ExtraTreesRegressor(criterion='mse', max_depth=50, max_features='sqrt',\n",
    "                    min_samples_split=4, n_estimators=50, warm_start=True)\n",
    "\n",
    "best_model.fit(X_train,y_train)\n",
    "best_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('laptop_price_regression.pickle','wb') as f:\n",
    "    pickle.dump(best_model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "173cd4c2288a411e28ef7d2bae2d3dec891b6be7ab06c2342038e4428c43a100"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
